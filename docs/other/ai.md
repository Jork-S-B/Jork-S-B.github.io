## 📌 LLM

Token  
与大模型交互时，用户提示词的自然语言会先转为token，提高效率

Embedding  
token是单个数字，可能无法准确表达其原意，因此向量化为多维数组，该过程即embedding

以上两者都LLM的一部分，而RAG Embedding，则是将一整段话向量化，准确识别语义。

## 📌 RAG

元数据（Metadata）: “关于数据的数据”，用于描述数据的属性、结构、来源、用途等信息。它本身不包含数据的具体内容，而是提供数据的管理和检索依据。

切片（Slicing）: 将大规模数据集或复杂结构按特定规则分割为更小、更易处理的部分。

召回（Recall）: 在信息检索或推荐系统中，从海量候选集中筛选出与目标相关的子集，作为后续排序或生成的输入。

透传（Transparent Transmission）: 数据在传输过程中不进行任何处理或修改，保持原始格式和内容，如同“透明管道”。

检索增强生成（Retrieval Augmented Generation）: 检索增强生成，将传统信息检索系统（如数据库）与生成式大语言模型进行结合，实现智能信息检索和生成。

## 📌 Agent

智能体，包括大脑-LLM，执行者-MCP客户端，动作-工具或脚本

诞生的直接诱因：1.早期大模型中，系统提示词仅单轮；2.无工具调用；3.静态的穷举

1. 分析消息内容，理解需求，分类后进入具体工作流。
2. 结合多种模型：包括LLM（大语言模型）、图像识别模型、OCR（光学字符识别）等，提取结构化数据。
3. 调用外部服务，请求缺失数据，保持上下文持久化。

MCP-model context protocol，是智能体中，执行者和工具、脚本（Skill）间调用的通信协议。

Function Calling，将用户提示词中的自然语言标准化为某种统一的格式如json，还可以根据语义调用对应的外部工具。即在对话中返回一个结构化的函数调用请求。

## 📌 Skill

定义：在智能体框架中，Skill通常定义 Agent 拥有的能力集合。

1.提示词：ai的人设，系统提示词一般优先级高于用户提示词

2.Command：提示词太长时，所以用md文件存放，通过Command调用对应的提示词。

3.Metadata元数据：文本太多时，花费token多，按场景拆分+md开头写提示信息（即元数据）；功能类似索引，以减少token消耗。

4.References：根据不同的用途，建立对应的路由进行按需调用，也称为渐进式披露。

5.Skill：包括References+Scripts，根据上下文，调用不同的提示词及对应的脚本（甚至让大模型自己写脚本），实现动态读取提示词。

Skill的功能类似Workflow（常见工具：n8n）的逻辑编排，但不同的是Skills由大模型驱动，更加灵活。

## 📌 其他

### 🚁 多模态

指的是 AI 模型能够理解和处理多种不同类型（模态）的信息，并能在它们之间建立联系。

常见的模态包括：

* 文本（语言、文字）
* 图像（照片、图表、绘画）
* 音频（语音、音乐、环境音）
* 视频（动态画面与声音的结合）

### 🚁 llm参数

Temperature

* 低温，严谨保守可预测，适合事实性回答如代码、翻译、数学题等。温度为0时，输出结果几乎相同。
* 高温，创意多样性，适合创意协作、头脑风暴。

Top_p   

* 低Top-p，模型只考虑概率最高、最集中的那极少一部分词汇，偏严谨保守。
* 高Top-p，模型会考虑更多词汇，相当于把取值范围扩大。

Top_k

* 低Top-k，模型只从最高的10个词中选，回答很集中。
* 高Top-k，模型从更多的词中选，多样性增加。

参数与人设提示词的关系：前者相当于硬件参数，改变数学概率；后者相当于软件参数，引导知识调用和风格模仿。

可以先给人设再搭配参数调整。