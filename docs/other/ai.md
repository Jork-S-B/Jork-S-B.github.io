## 📌 LLM

Token  
与大模型交互时，用户提示词的自然语言会先转为token，提高效率

Embedding  
token是单个数字，可能无法准确表达其原意，因此向量化为多维数组，该过程即embedding

以上两者都LLM的一部分，而RAG Embedding，则是将一整段话向量化，准确识别语义。

## 📌 RAG

元数据（Metadata）: “关于数据的数据”，用于描述数据的属性、结构、来源、用途等信息。它本身不包含数据的具体内容，而是提供数据的管理和检索依据。

切片（Slicing）: 将大规模数据集或复杂结构按特定规则分割为更小、更易处理的部分。

召回（Recall）: 在信息检索或推荐系统中，从海量候选集中筛选出与目标相关的子集，作为后续排序或生成的输入。

透传（Transparent Transmission）: 数据在传输过程中不进行任何处理或修改，保持原始格式和内容，如同“透明管道”。

检索增强生成（Retrieval Augmented Generation）: 检索增强生成，将传统信息检索系统（如数据库）与生成式大语言模型进行结合，实现智能信息检索和生成。

## 📌 Agent

智能体，包括大脑-LLM，执行者-MCP客户端，动作-工具或脚本

诞生的直接诱因：1.早期大模型中，系统提示词仅单轮；2.无工具调用；3.静态的穷举

1. 分析消息内容，理解需求，分类后进入具体工作流。
2. 结合多种模型：包括LLM（大语言模型）、图像识别模型、OCR（光学字符识别）等，提取结构化数据。
3. 调用外部服务，请求缺失数据，保持上下文持久化。

MCP-model context protocol，是智能体中，执行者和工具、脚本间调用的通信协议。

Function Calling，将用户提示词中的自然语言标准化为某种统一的格式如json，还可以根据语义调用对应的外部工具。即在对话中返回一个结构化的函数调用请求。

## 📌 Skill

1.提示词：ai的人设，系统提示词一般优先级高于用户提示词

2.Command：提示词太长时，所以用md文件存放，通过Command调用对应的提示词。

3.Metadata元数据：文本太多时，花费token多，按场景拆分+md开头写提示信息（即元数据）；功能类似索引。

4.References：根据不同的用途，建立对应的路由进行按需调用，也称为渐进式披露。

5.Skill：包括References+Scripts，调用不同的提示词及对应的脚本。

Skill的功能类似Workflow（常见工具：n8n）的逻辑编排，但不同的是Skills由大模型驱动，更加灵活。